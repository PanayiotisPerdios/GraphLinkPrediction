{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwRn9haPeztY"
   },
   "source": [
    "# **Graph Link Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHtDhEwGLUJu"
   },
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXieUFuNfDRJ"
   },
   "source": [
    "## 1.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "z2-lF2ydd8Vv",
    "outputId": "24150c2d-1099-4b97-b9c7-ad5425f999de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from karateclub import Node2Vec\n",
    "from dgl.data import CoraGraphDataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSJEhY_2f1hE"
   },
   "source": [
    "## 1.2. Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ev7hZH54gmMf"
   },
   "source": [
    "Φορτώνουμε το **CoraGraphDataset** dataset απο την βιβλιοθήκη **DGL**, το μετατρέπουμε σε **undirected  graph SimpleGraph** και παίρνουμε το μεγαλύτερο **connected component** διότι το γράφημα είναι **disconnected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGXB5tM0f0r4"
   },
   "outputs": [],
   "source": [
    "dataset = CoraGraphDataset()\n",
    "g_dgl = dataset[0]\n",
    "\n",
    "# Convert to undirected NetworkX graph\n",
    "nx_g = g_dgl.to_networkx()\n",
    "G_und = nx_g.to_undirected()\n",
    "G_simple = nx.Graph(G_und)\n",
    "\n",
    "# Get largest connected component\n",
    "components = list(nx.connected_components(G_simple))\n",
    "giant = max(components, key=len)\n",
    "print(\"Original nodes:\", g_dgl.num_nodes(), \"Original edges:\", g_dgl.num_edges())\n",
    "print(\"Number of components (undirected):\", len(components))\n",
    "print(\"Largest component size:\", len(giant))\n",
    "\n",
    "G = G_simple.subgraph(giant).copy()\n",
    "\n",
    "print(\"Nodes in largest component (undirected NetworkX):\", G.number_of_nodes())\n",
    "print(\"Edges in largest component (undirected NetworkX):\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jwa0_SyZiHSb"
   },
   "source": [
    "## 1.3. G_train preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMnVbl_bnhKB"
   },
   "source": [
    "Παίρνουμε προτεινόμενες ακμές από το γραφήμα **G** κάνοντας ελεγχος για **self-loops**, **multiple edges** και εάν έχει **bridges** μεταξύ ακμών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "feCDxsLuhF3_"
   },
   "outputs": [],
   "source": [
    "# Check for self-loops and multiple edges for candidate edges\n",
    "edges = set()\n",
    "\n",
    "for u,v in G.edges():\n",
    "    if u != v:\n",
    "        edges.add((min(u, v), max(u, v)))\n",
    "\n",
    "# Get G's bridges\n",
    "bridges = set()\n",
    "for u,v in nx.bridges(G):\n",
    "    edge = (min(u, v), max(u, v))\n",
    "    bridges.add(edge)\n",
    "\n",
    "# Check if candidate edges are bridges\n",
    "candidate_edges = []\n",
    "\n",
    "for e in edges:\n",
    "    if e not in bridges:\n",
    "        candidate_edges.append(e)\n",
    "\n",
    "candidate_num_edges = len(candidate_edges)\n",
    "percentage_to_remove = 0.10\n",
    "\n",
    "num_to_remove = int(candidate_num_edges * percentage_to_remove)\n",
    "\n",
    "edges_removed = []\n",
    "\n",
    "G_train = G.copy()\n",
    "\n",
    "candidate_edges_shuffled = candidate_edges.copy()\n",
    "random.shuffle(candidate_edges_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpJ3xl1OrYVu"
   },
   "source": [
    "Στην συνέχεια αφαιρούμε 10% των προτεινόμενων ακμών στο **G_Train** και μετα την αφαίρεση ακμών ελέγχουμε εάν το υπολειπόμενο γράφημα **G_Train** παραμένει **connected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "38jbPOf4rShh"
   },
   "outputs": [],
   "source": [
    "for u, v in candidate_edges_shuffled:\n",
    "    if len(edges_removed) == num_to_remove:\n",
    "        break\n",
    "\n",
    "    # Check degree first\n",
    "    if G_train.degree(u) <= 1 or G_train.degree(v) <= 1:\n",
    "        continue\n",
    "\n",
    "    # Check if edge is currently a bridge\n",
    "    if (u, v) in nx.bridges(G_train) or (v, u) in nx.bridges(G_train):\n",
    "        continue\n",
    "\n",
    "    G_train.remove_edge(u, v)\n",
    "    edges_removed.append((u, v))\n",
    "\n",
    "assert nx.is_connected(G_train), \"Training graph is disconnected\"\n",
    "\n",
    "# Test edges\n",
    "test_positive_edges = edges_removed\n",
    "nodes = list(G_train.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDqMvGG1uMjI"
   },
   "source": [
    "## 1.4. Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVzS_V_dvp7n"
   },
   "source": [
    "Παίρνουμε και τις **αρνητικές ακμές**(ακμές που δεν υπάρχουν μεταξύ κόμβων), έτσι ώστε να βάλουμε **labels** για θετίκες[1] και αρνητικές ακμες[0] που θα χρειαστούν για το **training** του μοντελού μας πιο μετά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ykTB9niEuaJW"
   },
   "outputs": [],
   "source": [
    "test_negative_edges = []\n",
    "\n",
    "for _ in range(num_to_remove):\n",
    "    u,v = random.sample(nodes, 2)\n",
    "\n",
    "    if not G_train.has_edge(u,v):\n",
    "        test_negative_edges.append((u,v))\n",
    "\n",
    "all_test_edges = test_positive_edges + test_negative_edges\n",
    "\n",
    "test_labels_heu = [1]*len(test_positive_edges) + [0]*len(test_negative_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uMEdo6fwrwY"
   },
   "source": [
    "# 2. Heuristic methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEyT7vEzxKxk"
   },
   "source": [
    "Τρέχουμε 3 ευριστικές μεθόδους **Common Neighbors**, **Adamic–Adar Index** και **Jaccard Coefficient** πάνω στο υπολειπόμενο γράφημα **G_train** χρησιμοποιώντας τις **labeled** συνολικές ακμές"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPpSkgW9xGDt"
   },
   "outputs": [],
   "source": [
    "common_neighbors_scores = []\n",
    "\n",
    "for u,v in all_test_edges:\n",
    "    common_neighbors = list(nx.common_neighbors(G_train, u,v))\n",
    "    score = len(common_neighbors)\n",
    "    common_neighbors_scores.append(score)\n",
    "\n",
    "aa_index_scores = []\n",
    "\n",
    "aa_index = list(nx.adamic_adar_index(G_train, all_test_edges))\n",
    "for u,v,score in aa_index:\n",
    "    aa_index_scores.append(score)\n",
    "\n",
    "jaccard_scores = []\n",
    "\n",
    "jaccard = list(nx.jaccard_coefficient(G_train, all_test_edges))\n",
    "for u,v,score in jaccard:\n",
    "    jaccard_scores.append(score)\n",
    "\n",
    "common_neighboors_auc = roc_auc_score(test_labels_heu, common_neighbors_scores)\n",
    "aa_index_auc = roc_auc_score(test_labels_heu, aa_index_scores)\n",
    "jaccard_auc = roc_auc_score(test_labels_heu, jaccard_scores)\n",
    "\n",
    "print(\"Common Neighbors AUC:\", common_neighboors_auc)\n",
    "print(\"Adamic-Adar AUC:\", aa_index_auc)\n",
    "print(\"Jaccard AUC:\", jaccard_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sE_e8h9DyRzE"
   },
   "source": [
    "# 3. Feature extraction, Shallow embeddings (Node2Vec) and MLP setup and training/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozDyS2ZByN_9"
   },
   "outputs": [],
   "source": [
    "# Shallow embeddings\n",
    "model = Node2Vec(dimensions=128,walk_length=80,walk_number=10,p=1,q=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDpzaZ4-zFfw"
   },
   "source": [
    "**Reindexing** διότι o **Node2Vec** απαιτεί από τους κόμβους του γραφήματος **G** να είναι αριθμημένοι σωστά απο **0...Ν-1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQG_lykRzEzi"
   },
   "outputs": [],
   "source": [
    "# Reindexing\n",
    "mapping = {}\n",
    "\n",
    "for new_index, old_node in enumerate(G.nodes()):\n",
    "    mapping[old_node] = new_index\n",
    "\n",
    "G_reindexed = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "model.fit(G_reindexed)\n",
    "embeddings = model.get_embedding()\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"First node embedding (first 5 values):\", embeddings[0][:5])\n",
    "print(\"Embedding mean/std:\", embeddings.mean(), embeddings.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bos-HbJtzHV6"
   },
   "source": [
    "Υπολόγιζουμε το **Hadamard product** **$h_{uv} = z_u \\odot z_v$** για κάθε ζευγος **$(u, v)$** **positive** και **negative** ακμών, ετσί ωστε να φτιαξούμε **embeddings** για τις ακμές"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Aob03juzzI5K"
   },
   "outputs": [],
   "source": [
    "# Hadamard product for test edges\n",
    "positive_edge_embeddings = []\n",
    "negative_edge_embeddings = []\n",
    "\n",
    "for u,v in  test_positive_edges:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    positive_edge_product = embeddings[u_i] * embeddings[v_i]\n",
    "    positive_edge_embeddings.append(positive_edge_product)\n",
    "\n",
    "for u,v in test_negative_edges:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    negative_edge_product = embeddings[u_i] * embeddings[v_i]\n",
    "    negative_edge_embeddings.append(negative_edge_product)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5duV599F1NJ"
   },
   "source": [
    "## 3.1. Test Set setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbJQ8mEXI5zO"
   },
   "source": [
    "Δημιουργούμε για το **test** σύνολο **feature embedings** **(X_train)** και **labels** **(Y_train)** για το τελικο **evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKvkbhbnFzAl"
   },
   "outputs": [],
   "source": [
    "# Test set\n",
    "X_test = np.array(positive_edge_embeddings + negative_edge_embeddings, dtype=np.float32)\n",
    "X_test = torch.tensor(X_test)\n",
    "print(\"X_test: \",X_test)\n",
    "\n",
    "test_labels = [1]*len(positive_edge_embeddings) + [0]*len(negative_edge_embeddings)\n",
    "Y_test = np.array(test_labels, dtype=np.float32)\n",
    "Y_test = torch.tensor(Y_test).unsqueeze(1)\n",
    "print(\"Y_test : \",Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFPXDnQ3KH6"
   },
   "source": [
    "## 3.2. Training edges and Train/Evaluation split sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd06rL7C8sZH"
   },
   "source": [
    "Χρησιμοποιούμε το γράφημα **G_train** για να παρουμε θετικές και αρνητικές ακμές"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0azGIsa53qK5"
   },
   "outputs": [],
   "source": [
    "# Training edges\n",
    "train_positive_edges = list(G_train.edges())\n",
    "train_nodes = list(G_train.nodes())\n",
    "train_negative_edges = []\n",
    "\n",
    "while len(train_negative_edges) < len(train_positive_edges):\n",
    "    u,v = random.sample(train_nodes, 2)\n",
    "    if not G_train.has_edge(u,v):\n",
    "        train_negative_edges.append((u, v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BlqNqQz5bNp"
   },
   "source": [
    "Χωρίζουμε τα **train_positive_edges** και **train_negative_edges** σε **80% train** και **20% validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Mf_vaRFs5_Ah"
   },
   "outputs": [],
   "source": [
    "# Evaluation and Train split sets\n",
    "\n",
    "train_possitive, val_possitive = train_test_split(train_positive_edges,\n",
    "                                        test_size = 0.2,\n",
    "                                        random_state = 42,\n",
    "                                        shuffle = True)\n",
    "\n",
    "train_negative, val_negative = train_test_split(train_negative_edges,\n",
    "                                        test_size = 0.2,\n",
    "                                        random_state = 42,\n",
    "                                        shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rpt1-bvA6EpB"
   },
   "source": [
    "Δημιουργούμε για το **train** σύνολο **feature embedings** **(X_train)** και **labels** **(Y_train)** για να εκπαιδεύσουμε το μοντέλο μας"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IALNwH_o6LZ7"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for u,v in train_possitive:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    edge_embedding = embeddings[u_i] * embeddings[v_i]\n",
    "    X_train.append(edge_embedding)\n",
    "    Y_train.append(1)\n",
    "\n",
    "for u,v in train_negative:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    edge_embedding = embeddings[u_i] * embeddings[v_i]\n",
    "    X_train.append(edge_embedding)\n",
    "    Y_train.append(0)\n",
    "\n",
    "X_train = torch.tensor(np.array(X_train), dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Shuffle\n",
    "perm = torch.randperm(X_train.size(0))\n",
    "\n",
    "X_train = X_train[perm]\n",
    "Y_train = Y_train[perm]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"First 5 labels:\", Y_train[:5].T)\n",
    "print(\"Positive/Negative ratio:\",Y_train.sum().item(), \"/\", len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGTZ-6lf6RlN"
   },
   "source": [
    "Δημιουργούμε για το **validation** σύνολο **feature embedings** **(X_val)** και **labels** **(Y_val)** για το συνεχές **monitoring** των αποτελεσμάτων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9toY4aXx6Q_J"
   },
   "outputs": [],
   "source": [
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for u, v in val_possitive:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    edge_embedding = embeddings[u_i] * embeddings[v_i]\n",
    "    X_val.append(edge_embedding)\n",
    "    Y_val.append(1)\n",
    "\n",
    "for u, v in val_negative:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    edge_embedding = embeddings[u_i] * embeddings[v_i]\n",
    "    X_val.append(edge_embedding)\n",
    "    Y_val.append(0)\n",
    "\n",
    "X_val = torch.tensor(np.array(X_val), dtype=torch.float32)\n",
    "Y_val = torch.tensor(Y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Shuffle\n",
    "perm = torch.randperm(X_val.size(0))\n",
    "\n",
    "X_val = X_val[perm]\n",
    "Y_val = Y_val[perm]\n",
    "\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"Y_val shape:\", Y_val.shape)\n",
    "print(\"First 5 labels:\", Y_val[:5].T)\n",
    "print(\"Positive/Negative ratio:\", Y_val.sum().item(), \"/\", len(Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2PCYoBbAubK"
   },
   "source": [
    "# 3.3) Simple MLP setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9qX7TF9CqQG"
   },
   "source": [
    "To μοντέλο MLP εχει 3 Linear Layers, για **criterion** χρησιμοποιούμε των **BCEWithLogitsLoss** της βιβλιοθήκης **torch.nn** και για **optimizer** τον **Adam** της βιβλιοθήκης **torch.optim**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CmJ7ZTT3BCk7"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,embedding_dimension):\n",
    "        super(MLP,self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(embedding_dimension, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "# Setup model\n",
    "embedding_dimension = embeddings.shape[1]\n",
    "model_mlp = MLP(embedding_dimension=embedding_dimension)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model_mlp.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OzyrkjWA_JQ"
   },
   "source": [
    "# 3.4) Train MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPlwr7y7CLvJ"
   },
   "source": [
    "Περνάμε στις παραμετρους τα **feature embedings** **(X_train)** και **labels** **(Y_train)** του συνολου **validation** και **train** τον **optimizer** και **criterion** και των αριθμο passthrough στο **training set** **(epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Hkdin1TBWQE"
   },
   "outputs": [],
   "source": [
    "def train(model, X_train, Y_train, X_val, Y_val, criterion, optimizer, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(X_train)\n",
    "        loss = criterion(logits, Y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits = model(X_val)\n",
    "            val_probs = torch.sigmoid(val_logits)\n",
    "            val_auc = roc_auc_score(Y_val.cpu().numpy(), val_probs.cpu().numpy())\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "# Train model\n",
    "train(model = model_mlp,\n",
    "      X_train = X_train,\n",
    "      Y_train = Y_train,\n",
    "      X_val = X_val,\n",
    "      Y_val = Y_val,\n",
    "      criterion = criterion,\n",
    "      optimizer = optimizer,\n",
    "      epochs = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsxsQl89BqXE"
   },
   "source": [
    "# 3.5) Evaluate MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHJRgEGDFR9G"
   },
   "source": [
    "Τέλος βγαζουμε το **AUC** για το **test set** και **validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgoPWibGBkgY"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        auc = roc_auc_score(Y.cpu().numpy(), probs.cpu().numpy())\n",
    "    return auc\n",
    "\n",
    "# Final evaluation\n",
    "val_auc = evaluate(model_mlp, X_val, Y_val)\n",
    "test_auc = evaluate(model_mlp, X_test, Y_test)\n",
    "\n",
    "print(\"Final Val AUC:\", val_auc)\n",
    "print(\"Final Test AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) GNN setup and training/evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Convert training graph from NetworkX to DGL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τo **GNN** χρειάζετε το γράφημα να είναι σε **DGL** object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train_dgl = dgl.from_networkx(G_train)\n",
    "g_train_dgl = dgl.add_self_loop(g_train_dgl)\n",
    "\n",
    "node_list = list(G_train.nodes())\n",
    "g_train_dgl.ndata[\"feat\"] = g_dgl.ndata[\"feat\"][torch.tensor(node_list)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) Test/Val split sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Χωρίζουμε τα **test_positive_edges** και **test_negative_edges** σε **50% test** και **50% validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_positive_edges, test_positive_edges = train_test_split(\n",
    "    test_positive_edges,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_negative_edges, test_negative_edges = train_test_split(\n",
    "    test_negative_edges,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3) GCN encoder setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ο **GCN encoder** εχει 2 Layers με σκοπο να φτιάξει **embeddings** κόμβων\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, out_feats):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, out_feats)\n",
    "        \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g,h)\n",
    "        return h\n",
    "\n",
    "# Setting up encoder (GCN)\n",
    "in_feats = g_train_dgl.ndata[\"feat\"].shape[1]\n",
    "h_feats = 64\n",
    "out_feats = 64\n",
    "encoder = GCN(in_feats=in_feats, h_feats=h_feats, out_feats=out_feats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4) Setup dot product decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ο **dot product** χρησιμοποιήτε για **link prediction**, πέρνει δύο **embeddings** κόμβων και βγάζει ενα **score** για κάθε ακμή"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(z, edges):\n",
    "    u = edges[:,0] \n",
    "    v = edges[:,1]\n",
    "    y_hat = (z[u] * z[v]).sum(dim=1)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5) Reindex test/val edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κάνουμε **reindex** τα **test edges** και **val edges** του **NetworkX training graph (G_train)** για να ταιριάξουν στο **DGL training graph (g_train_dgl)** έτσι ώστε να τα έχουμε έτοιμα για **evaluation** μετά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex test edges\n",
    "new_mapping = {}\n",
    "positive_mapped_test_edges = []\n",
    "negative_mapped_test_edges = []\n",
    "\n",
    "for new_index, old_node in enumerate(G_train.nodes()):\n",
    "    new_mapping[old_node] = new_index\n",
    "\n",
    "for u, v in test_positive_edges:\n",
    "    if u in new_mapping and v in new_mapping:\n",
    "        u_i = new_mapping[u]\n",
    "        v_i = new_mapping[v]\n",
    "        positive_mapped_test_edges.append((u_i, v_i))\n",
    "\n",
    "for u, v in test_negative_edges:\n",
    "    if u in new_mapping and v in new_mapping:\n",
    "        u_i = new_mapping[u]\n",
    "        v_i = new_mapping[v]\n",
    "        negative_mapped_test_edges.append((u_i, v_i))\n",
    "\n",
    "# Reindex val edges\n",
    "positive_mapped_val_edges = []\n",
    "negative_mapped_val_edges = []\n",
    "\n",
    "for u, v in val_positive_edges:\n",
    "    if u in new_mapping and v in new_mapping:\n",
    "        u_i = new_mapping[u]\n",
    "        v_i = new_mapping[v]\n",
    "        positive_mapped_val_edges.append((u_i, v_i))\n",
    "\n",
    "for u, v in val_negative_edges:\n",
    "    if u in new_mapping and v in new_mapping:\n",
    "        u_i = new_mapping[u]\n",
    "        v_i = new_mapping[v]\n",
    "        negative_mapped_val_edges.append((u_i, v_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6) Train GNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Περνάμε στις παραμετρους το **encoder model (GCN)**, το **training graph**, τα **features**, τον **optimizer (Adam)**, τον **decoder (dot_product)**, των αριθμό **epoch** για το **training loop** και τελος ποσα αρνητικα δείγματα θελουμε ανα θετική ακμή, χρησιμοποιούμε **Binary cross entroopy with logits** για **loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gnn(model, decoder, g, node_feats, pos_edges, neg_edges):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = model(g, node_feats)\n",
    "        positive_edges = torch.tensor(pos_edges)\n",
    "        negative_edges = torch.tensor(neg_edges)\n",
    "\n",
    "        positive_score = decoder(z, positive_edges)\n",
    "        negative_score = decoder(z, negative_edges)\n",
    "\n",
    "        scores = torch.cat([positive_score, negative_score])\n",
    "\n",
    "        positive_label = torch.ones(len(positive_score)) \n",
    "        negative_label = torch.zeros(len(negative_score))\n",
    "\n",
    "        labels = torch.cat([positive_label, negative_label])\n",
    "\n",
    "\n",
    "        auc = roc_auc_score(labels, scores)\n",
    "\n",
    "    return auc\n",
    "\n",
    "def train_gnn(model, g_train, node_feats, val_pos, val_neg, optimizer, decoder, epochs=100, neg_samples=1):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # Encoding edges\n",
    "        z = model(g_train, node_feats)\n",
    "\n",
    "        # Getting possitive edges\n",
    "        u, v = g_train.edges()\n",
    "        positive_edges = torch.stack([u, v], dim=1)\n",
    "        positive_score = decoder(z, positive_edges)\n",
    "        positive_label = torch.ones_like(positive_score)\n",
    "\n",
    "        # Negative sampling\n",
    "        num_negative = u.shape[0] * neg_samples\n",
    "        negative_u = torch.randint(0, g_train.num_nodes(), (num_negative,))\n",
    "        negative_v = torch.randint(0, g_train.num_nodes(), (num_negative,))\n",
    "        negative_edges = torch.stack([negative_u, negative_v], dim=1)\n",
    "        negative_score = decoder(z, negative_edges)\n",
    "        negative_label = torch.zeros_like(negative_score)\n",
    "\n",
    "        \n",
    "        scores = torch.cat([positive_score, negative_score])\n",
    "        labels = torch.cat([positive_label, negative_label])\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "             val_auc = evaluate_gnn(\n",
    "                    model=model,\n",
    "                    decoder=decoder,\n",
    "                    g=g_train,\n",
    "                    node_feats=node_feats,\n",
    "                    pos_edges=val_pos,\n",
    "                    neg_edges=val_neg\n",
    "                )\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "# Setting up optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=0.01)\n",
    "\n",
    "# Train model\n",
    "\n",
    "train_gnn(\n",
    "    model = encoder,\n",
    "    g_train = g_train_dgl,\n",
    "    node_feats = g_train_dgl.ndata[\"feat\"],\n",
    "    val_pos = positive_mapped_val_edges,\n",
    "    val_neg = negative_mapped_val_edges,\n",
    "    optimizer = optimizer,\n",
    "    decoder = dot_product,\n",
    "    epochs = 100,\n",
    "    neg_samples = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.7) Evaluate GNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τέλος βγαζουμε το **AUC** για τις **test** θετικές και αρνητικές ακμές"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Evaluation \n",
    "test_auc = evaluate_gnn(\n",
    "    model = encoder,\n",
    "    decoder = dot_product,\n",
    "    g = g_train_dgl,\n",
    "    node_feats = g_train_dgl.ndata[\"feat\"],\n",
    "    pos_edges = positive_mapped_test_edges,\n",
    "    neg_edges = negative_mapped_test_edges\n",
    ")\n",
    "\n",
    "val_auc = evaluate_gnn(\n",
    "    model=encoder,\n",
    "    decoder=dot_product,\n",
    "    g=g_train_dgl,\n",
    "    node_feats=g_train_dgl.ndata[\"feat\"],\n",
    "    pos_edges=positive_mapped_val_edges,\n",
    "    neg_edges=negative_mapped_val_edges\n",
    ")\n",
    "\n",
    "print(\"Final Val AUC:\", val_auc)\n",
    "print(\"Final Test AUC:\", test_auc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
