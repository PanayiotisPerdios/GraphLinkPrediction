{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwRn9haPeztY"
   },
   "source": [
    "# **Graph Link Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHtDhEwGLUJu"
   },
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXieUFuNfDRJ"
   },
   "source": [
    "## 1.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "z2-lF2ydd8Vv",
    "outputId": "24150c2d-1099-4b97-b9c7-ad5425f999de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from karateclub import Node2Vec\n",
    "from dgl.data import CoraGraphDataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSJEhY_2f1hE"
   },
   "source": [
    "## 1.2. Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ev7hZH54gmMf"
   },
   "source": [
    "Φορτώνουμε το **CoraGraphDataset** dataset απο την βιβλιοθήκη **DGL**, το μετατρέπουμε σε **undirected graph** και παίρνουμε το μεγαλύτερο **connected component**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rGXB5tM0f0r4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Original nodes: 2708 Original edges: 10556\n",
      "Number of components (undirected): 78\n",
      "Largest component size: 2485\n",
      "Nodes in largest component (undirected): 2485\n",
      "Edges in largest component (undirected): 5069\n"
     ]
    }
   ],
   "source": [
    "dataset = CoraGraphDataset()\n",
    "g = dataset[0]\n",
    "\n",
    "nx_g = g.to_networkx()\n",
    "G_und = nx_g.to_undirected()\n",
    "\n",
    "G_simple = nx.Graph(G_und)\n",
    "\n",
    "components = list(nx.connected_components(G_simple))\n",
    "giant = max(components, key=len)\n",
    "print(\"Original nodes:\", g.num_nodes(), \"Original edges:\", g.num_edges())\n",
    "print(\"Number of components (undirected):\", len(components))\n",
    "print(\"Largest component size:\", len(giant))\n",
    "\n",
    "G = G_simple.subgraph(giant).copy()\n",
    "\n",
    "print(\"Nodes in largest component (undirected):\", G.number_of_nodes())\n",
    "print(\"Edges in largest component (undirected):\", G.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jwa0_SyZiHSb"
   },
   "source": [
    "## 1.3. G_train preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMnVbl_bnhKB"
   },
   "source": [
    "Παίρνουμε προτεινόμενες ακμές από το γραφήμα **G** κάνοντας ελεγχος για **self-loops**, **multiple edges** και εάν έχει **bridges** μεταξύ ακμών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "feCDxsLuhF3_"
   },
   "outputs": [],
   "source": [
    "# Check for self-loops and multiple edges for candidate edges\n",
    "edges = set()\n",
    "\n",
    "for u,v in G.edges():\n",
    "    if u != v:\n",
    "        edges.add((min(u, v), max(u, v)))\n",
    "\n",
    "# Get G's bridges\n",
    "bridges = set()\n",
    "for u,v in nx.bridges(G):\n",
    "    edge = (min(u, v), max(u, v))\n",
    "    bridges.add(edge)\n",
    "\n",
    "# Check if candidate edges are bridges\n",
    "candidate_edges = []\n",
    "\n",
    "for e in edges:\n",
    "    if e not in bridges:\n",
    "        candidate_edges.append(e)\n",
    "\n",
    "candidate_num_edges = len(candidate_edges)\n",
    "percentage_to_remove = 0.10\n",
    "\n",
    "num_to_remove = int(candidate_num_edges * percentage_to_remove)\n",
    "\n",
    "edges_removed = []\n",
    "\n",
    "G_train = G.copy()\n",
    "\n",
    "candidate_edges_shuffled = candidate_edges.copy()\n",
    "random.shuffle(candidate_edges_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpJ3xl1OrYVu"
   },
   "source": [
    "Στην συνέχεια αφαιρούμε 10% των προτεινόμενων ακμών στο **G_Train** και μετα την αφαίρεση ακμών ελέγχουμε εάν το υπολειπόμενο γράφημα **G_Train** παραμένει **connected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "38jbPOf4rShh"
   },
   "outputs": [],
   "source": [
    "for u, v in candidate_edges_shuffled:\n",
    "    if len(edges_removed) == num_to_remove:\n",
    "        break\n",
    "\n",
    "    # Check degree first\n",
    "    if G_train.degree(u) <= 1 or G_train.degree(v) <= 1:\n",
    "        continue\n",
    "\n",
    "    # Check if edge is currently a bridge\n",
    "    if (u, v) in nx.bridges(G_train) or (v, u) in nx.bridges(G_train):\n",
    "        continue\n",
    "\n",
    "    G_train.remove_edge(u, v)\n",
    "    edges_removed.append((u, v))\n",
    "\n",
    "assert nx.is_connected(G_train), \"Training graph is disconnected\"\n",
    "\n",
    "# Test edges\n",
    "test_positive_edges = edges_removed\n",
    "nodes = list(G_train.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDqMvGG1uMjI"
   },
   "source": [
    "## 1.4. Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVzS_V_dvp7n"
   },
   "source": [
    "Παίρνουμε και τις **αρνητικές ακμές**(ακμές που δεν υπάρχουν μεταξύ κόμβων), έτσι ώστε να βάλουμε **labels** για θετίκες[1] και αρνητικές ακμες[0] που θα χρειαστούν για το **training** του μοντελού μας πιο μετά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ykTB9niEuaJW"
   },
   "outputs": [],
   "source": [
    "test_negative_edges = []\n",
    "\n",
    "for _ in range(num_to_remove):\n",
    "    u,v = random.sample(nodes, 2)\n",
    "\n",
    "    if not G_train.has_edge(u,v):\n",
    "        test_negative_edges.append((u,v))\n",
    "\n",
    "all_test_edges = test_positive_edges + test_negative_edges\n",
    "\n",
    "test_labels_heu = [1]*len(test_positive_edges) + [0]*len(test_negative_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uMEdo6fwrwY"
   },
   "source": [
    "# 2. Heuristic methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEyT7vEzxKxk"
   },
   "source": [
    "Τρέχουμε 3 ευριστικές μεθόδους **Common Neighbors**, **Adamic–Adar Index** και **Jaccard Coefficient** πάνω στο υπολειπόμενο γράφημα **G_train** χρησιμοποιώντας τις **labeled** συνολικές ακμές"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cPpSkgW9xGDt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Neighbors AUC: 0.756887906020227\n",
      "Adamic-Adar AUC: 0.7575828004244489\n",
      "Jaccard AUC: 0.7564113399254396\n"
     ]
    }
   ],
   "source": [
    "common_neighbors_scores = []\n",
    "\n",
    "for u,v in all_test_edges:\n",
    "    common_neighbors = list(nx.common_neighbors(G_train, u,v))\n",
    "    score = len(common_neighbors)\n",
    "    common_neighbors_scores.append(score)\n",
    "\n",
    "aa_index_scores = []\n",
    "\n",
    "aa_index = list(nx.adamic_adar_index(G_train, all_test_edges))\n",
    "for u,v,score in aa_index:\n",
    "    aa_index_scores.append(score)\n",
    "\n",
    "jaccard_scores = []\n",
    "\n",
    "jaccard = list(nx.jaccard_coefficient(G_train, all_test_edges))\n",
    "for u,v,score in jaccard:\n",
    "    jaccard_scores.append(score)\n",
    "\n",
    "common_neighboors_auc = roc_auc_score(test_labels_heu, common_neighbors_scores)\n",
    "aa_index_auc = roc_auc_score(test_labels_heu, aa_index_scores)\n",
    "jaccard_auc = roc_auc_score(test_labels_heu, jaccard_scores)\n",
    "\n",
    "print(\"Common Neighbors AUC:\", common_neighboors_auc)\n",
    "print(\"Adamic-Adar AUC:\", aa_index_auc)\n",
    "print(\"Jaccard AUC:\", jaccard_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sE_e8h9DyRzE"
   },
   "source": [
    "# 3. Feature extraction and Shallow embeddings (Node2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ozDyS2ZByN_9"
   },
   "outputs": [],
   "source": [
    "# Shallow embeddings\n",
    "model = Node2Vec(dimensions=128,walk_length=80,walk_number=10,p=1,q=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDpzaZ4-zFfw"
   },
   "source": [
    "**Reindexing** διότι o **Node2Vec** απαιτεί από τους κόμβους του γραφήματος **G** να είναι αριθμημένοι σωστά απο **0...Ν-1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OQG_lykRzEzi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64758724 -0.13368495 -0.9804726  ...  0.43957293  0.6912305\n",
      "  -0.4849253 ]\n",
      " [ 2.144873    2.0424497  -0.04787344 ... -1.7461174  -0.4515117\n",
      "  -0.18907961]\n",
      " [ 0.60790217  0.6730887  -0.38599363 ... -0.01238189 -0.45242012\n",
      "   0.7232726 ]\n",
      " ...\n",
      " [-1.364041   -0.9063817   0.04086403 ... -0.27620184 -1.2397317\n",
      "  -0.50661546]\n",
      " [ 0.76336634 -1.1451117  -0.05941312 ... -0.3435472  -0.27481073\n",
      "   0.6760372 ]\n",
      " [ 0.53560096 -0.52513343 -1.0378287  ...  0.01657413 -0.90016294\n",
      "  -0.48899803]]\n",
      "Embeddings shape: (2485, 128)\n",
      "First node embedding (first 5 values): [ 0.64758724 -0.13368495 -0.9804726   0.88186586  0.80770665]\n",
      "Embedding mean/std: -0.018136656 0.84856576\n"
     ]
    }
   ],
   "source": [
    "# Reindexing\n",
    "mapping = {}\n",
    "\n",
    "for new_index, old_node in enumerate(G.nodes()):\n",
    "    mapping[old_node] = new_index\n",
    "\n",
    "G_reindexed = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "model.fit(G_reindexed)\n",
    "embeddings = model.get_embedding()\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"First node embedding (first 5 values):\", embeddings[0][:5])\n",
    "print(\"Embedding mean/std:\", embeddings.mean(), embeddings.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bos-HbJtzHV6"
   },
   "source": [
    "Υπολόγιζουμε το **Hadamard product** **$h_{uv} = z_u \\odot z_v$** για κάθε ζευγος **$(u, v)$** **positive** και **negative** ακμών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Aob03juzzI5K"
   },
   "outputs": [],
   "source": [
    "# Hadamard product for test edges\n",
    "positive_edge_embeddings = []\n",
    "negative_edge_embeddings = []\n",
    "\n",
    "for u,v in  test_positive_edges:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    positive_edge_product = embeddings[u_i] * embeddings[v_i]\n",
    "    positive_edge_embeddings.append(positive_edge_product)\n",
    "\n",
    "for u,v in test_negative_edges:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    negative_edge_product = embeddings[u_i] * embeddings[v_i]\n",
    "    negative_edge_embeddings.append(negative_edge_product)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5duV599F1NJ"
   },
   "source": [
    "## 3.1. Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbJQ8mEXI5zO"
   },
   "source": [
    "Δημιουργούμε για το **test** σύνολο **feature embedings** **(X_train)** και **labels** **(Y_train)** για το τελικο **evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TKvkbhbnFzAl"
   },
   "outputs": [],
   "source": [
    "# Test set\n",
    "X_test = np.array(positive_edge_embeddings + negative_edge_embeddings, dtype=np.float32)\n",
    "X_test = torch.tensor(X_test)\n",
    "#print(\"X_test: \",X_test)\n",
    "\n",
    "test_labels = [1]*len(positive_edge_embeddings) + [0]*len(negative_edge_embeddings)\n",
    "Y_test = np.array(test_labels, dtype=np.float32)\n",
    "Y_test = torch.tensor(Y_test).unsqueeze(1)\n",
    "#print(\"Y_test : \",Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFPXDnQ3KH6"
   },
   "source": [
    "## 3.2. Training edges and Train/Evaluation split sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd06rL7C8sZH"
   },
   "source": [
    "Χρησιμοποιούμε το γράφημα **G_train** για να παρουμε θετικές και αρνητικές ακμές"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0azGIsa53qK5"
   },
   "outputs": [],
   "source": [
    "# Training edges\n",
    "train_positive_edges = list(G_train.edges())\n",
    "train_nodes = list(G_train.nodes())\n",
    "train_negative_edges = []\n",
    "\n",
    "while len(train_negative_edges) < len(train_positive_edges):\n",
    "    u,v = random.sample(train_nodes, 2)\n",
    "    if not G_train.has_edge(u,v):\n",
    "        train_negative_edges.append((u, v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BlqNqQz5bNp"
   },
   "source": [
    "Χωρίζουμε τα **train_positive_edges** και **train_negative_edges** σε **80% train** και **20% validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Mf_vaRFs5_Ah"
   },
   "outputs": [],
   "source": [
    "# Evaluation and Train split sets\n",
    "\n",
    "train_possitive, val_possitive = train_test_split(train_positive_edges,\n",
    "                                        test_size = 0.2,\n",
    "                                        random_state = 42,\n",
    "                                        shuffle = True)\n",
    "\n",
    "train_negative, val_negative = train_test_split(train_negative_edges,\n",
    "                                        test_size = 0.2,\n",
    "                                        random_state = 42,\n",
    "                                        shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rpt1-bvA6EpB"
   },
   "source": [
    "Δημιουργούμε για το **train** σύνολο **feature embedings** **(X_train)** και **labels** **(Y_train)** για να εκπαιδεύσουμε το μοντέλο μας"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IALNwH_o6LZ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([7370, 128])\n",
      "Y_train shape: torch.Size([7370, 1])\n",
      "First 5 labels: tensor([[0., 0., 0., 1., 1.]])\n",
      "Positive/Negative ratio: 3685.0 / 7370\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for u,v in train_possitive:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    edge_embedding = embeddings[u_i] * embeddings[v_i]\n",
    "    X_train.append(edge_embedding)\n",
    "    Y_train.append(1)\n",
    "\n",
    "for u,v in train_negative:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    edge_embedding = embeddings[u_i] * embeddings[v_i]\n",
    "    X_train.append(edge_embedding)\n",
    "    Y_train.append(0)\n",
    "\n",
    "X_train = torch.tensor(np.array(X_train), dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "perm = torch.randperm(X_train.size(0))\n",
    "\n",
    "X_train = X_train[perm]\n",
    "Y_train = Y_train[perm]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"First 5 labels:\", Y_train[:5].T)\n",
    "print(\"Positive/Negative ratio:\",Y_train.sum().item(), \"/\", len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGTZ-6lf6RlN"
   },
   "source": [
    "Δημιουργούμε για το **validation** σύνολο **feature embedings** **(X_train)** και **labels** **(Y_train)** για το συνεχές **monitoring** των αποτελεσμάτων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9toY4aXx6Q_J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val shape: torch.Size([1844, 128])\n",
      "Y_val shape: torch.Size([1844, 1])\n",
      "First 5 labels: tensor([[0., 1., 1., 0., 0.]])\n",
      "Positive/Negative ratio: 922.0 / 1844\n"
     ]
    }
   ],
   "source": [
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for u, v in val_possitive:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    edge_embedding = embeddings[u_i] * embeddings[v_i]\n",
    "    X_val.append(edge_embedding)\n",
    "    Y_val.append(1)\n",
    "\n",
    "for u, v in val_negative:\n",
    "    u_i = mapping[u]\n",
    "    v_i = mapping[v]\n",
    "    edge_embedding = embeddings[u_i] * embeddings[v_i]\n",
    "    X_val.append(edge_embedding)\n",
    "    Y_val.append(0)\n",
    "\n",
    "X_val = torch.tensor(np.array(X_val), dtype=torch.float32)\n",
    "Y_val = torch.tensor(Y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Shuffle\n",
    "perm = torch.randperm(X_val.size(0))\n",
    "\n",
    "X_val = X_val[perm]\n",
    "Y_val = Y_val[perm]\n",
    "\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"Y_val shape:\", Y_val.shape)\n",
    "print(\"First 5 labels:\", Y_val[:5].T)\n",
    "print(\"Positive/Negative ratio:\", Y_val.sum().item(), \"/\", len(Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2PCYoBbAubK"
   },
   "source": [
    "# 4) Simple MLP setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9qX7TF9CqQG"
   },
   "source": [
    "To μοντέλο MLP εχει 3 Linear Layers για **criterion** χρησιμοποιούμε των **BCEWithLogitsLoss** της βιβλιοθήκης **torch.nn** και για **optimizer** τον **Adam** της βιβλιοθήκης **torch.optim**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CmJ7ZTT3BCk7"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,embedding_dimension):\n",
    "        super(MLP,self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(embedding_dimension, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "# Setup model\n",
    "embedding_dimension = embeddings.shape[1]\n",
    "model_mlp = MLP(embedding_dimension=embedding_dimension)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model_mlp.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OzyrkjWA_JQ"
   },
   "source": [
    "# 5) Train MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPlwr7y7CLvJ"
   },
   "source": [
    "Περνάμε στις παραμετρους τα **feature embedings** **(X_train)** και **labels** **(Y_train)** του συνολου **validation** και **train** τον **optimizer** και **criterion** και των αριθμο passthrough στο **training set** **(epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3Hkdin1TBWQE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Loss: 0.1313 | Val AUC: 0.9403\n",
      "Epoch 001 | Loss: 0.1271 | Val AUC: 0.9406\n",
      "Epoch 002 | Loss: 0.1230 | Val AUC: 0.9409\n",
      "Epoch 003 | Loss: 0.1188 | Val AUC: 0.9412\n",
      "Epoch 004 | Loss: 0.1148 | Val AUC: 0.9414\n"
     ]
    }
   ],
   "source": [
    "def train(model, X_train, Y_train, X_val, Y_val, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(X_train)\n",
    "        loss = criterion(logits, Y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits = model(X_val)\n",
    "            val_probs = torch.sigmoid(val_logits)\n",
    "            val_auc = roc_auc_score(Y_val.cpu().numpy(), val_probs.cpu().numpy())\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "# Train model\n",
    "train(model = model_mlp,\n",
    "      X_train = X_train,\n",
    "      Y_train = Y_train,\n",
    "      X_val = X_val,\n",
    "      Y_val = Y_val,\n",
    "      criterion = criterion,\n",
    "      optimizer = optimizer,\n",
    "      epochs = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsxsQl89BqXE"
   },
   "source": [
    "# 6) Evaluate MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHJRgEGDFR9G"
   },
   "source": [
    "Τέλος βγαζουμε το **AUC** για το **test set** και **validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jgoPWibGBkgY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Val AUC: 0.941364618084801\n",
      "Final Test AUC: 0.9517283150688791\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X, Y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        auc = roc_auc_score(Y.cpu().numpy(), probs.cpu().numpy())\n",
    "    return auc\n",
    "\n",
    "# Final evaluation\n",
    "val_auc = evaluate(model_mlp, X_val, Y_val)\n",
    "test_auc = evaluate(model_mlp, X_test, Y_test)\n",
    "\n",
    "print(\"Final Val AUC:\", val_auc)\n",
    "print(\"Final Test AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
